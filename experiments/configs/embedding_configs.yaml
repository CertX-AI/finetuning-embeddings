triplet:
  script: "exp_finetuning_embeddings_triplet.py"
  model-parameters:
    - num_train_epochs: [2, 3]
    - experiment_name: "finetuning_embeddings_triplet_test"
    - run_name: "test_triplet"
    - output_dir: "experiments/results/triplet/mpnet-base-all-nli-triplet/final"
    - learning_rate: [5e-4, 2e-5]
    - loss_function:
        - "MultipleNegativesRankingLoss"
        - "CachedMultipleNegativesRankingLoss"
        - "TripletLoss"
    - model_name:
        - "all-mpnet-base-v2"
        - "nomic-ai/nomic-embed-text-v1.5"
        - "nomic-ai/nomic-embed-text-v2-moe"
        - "BAAI/bge-base-en-v1.5"
        - "BAAI/bge-large-en-v1.5"
        - "Alibaba-NLP/gte-large-en-v1.5"

contrastive:
  script: "exp_finetuning_embeddings_contrastive.py"
  model-parameters:
    - num_train_epochs: [2, 3, 4]
    - experiment_name: "finetuning_embeddings_contrastive_test"
    - run_name: "test_contrastive"
    - output_dir: "experiments/results/contrastive/mpnet-base-all-nli-contrastive/final"
    - learning_rate:
        - 1e-3
        - 5e-4
        - 3e-4
        - 1e-4
        - 4e-5
        - 2e-5
        - 1e-5
    - loss_function:
        - "ContrastiveLoss"
        - "OnlineContrastiveLoss"
    - model_name:
        - "all-mpnet-base-v2"
        - "nomic-ai/nomic-embed-text-v1.5"
        - "nomic-ai/nomic-embed-text-v2-moe"
        - "BAAI/bge-base-en-v1.5"
        - "BAAI/bge-large-en-v1.5"
        - "Alibaba-NLP/gte-large-en-v1.5"

anchor_positive_pairs:
  script: "exp_finetuning_embeddings_matryoshka_anchor_positive_pairs.py"
  model-parameters:
    - num_train_epochs: [2, 3]
    - experiment_name: "finetuning_embeddings_anchor_positive_pairs_test"
    - run_name: "test_anchor_positive_pairs"
    - output_dir: "experiments/results/anchor_positive_pairs/mpnet-base-all-nli-matryoshka"
    - learning_rate: [5e-4, 2e-5]
    - loss_function:
        - "MultipleNegativesRankingLoss"
        - "CachedMultipleNegativesRankingLoss"
        - "MultipleNegativesSymmetricRankingLoss"
        - "CachedMultipleNegativesSymmetricRankingLoss"
        - "MegaBatchMarginLoss"
    - model_name:
        - "all-mpnet-base-v2"
        - "nomic-ai/nomic-embed-text-v1.5"
        - "nomic-ai/nomic-embed-text-v2-moe"
        - "BAAI/bge-base-en-v1.5"
        - "BAAI/bge-large-en-v1.5"
        - "Alibaba-NLP/gte-large-en-v1.5"

matryoshka:
  script: "exp_finetuning_embeddings_matryoshka.py"
  model-parameters:
    - num_train_epochs: [2, 3]
    - experiment_name: "finetuning_embeddings_matryoshka_test"
    - run_name: "test_matryoshka"
    - output_dir: "experiments/results/matryoshka/mpnet-base-all-nli-matryoshka"
    - learning_rate: [5e-4, 2e-5]
    - loss_function:
        - "MultipleNegativesRankingLoss"
        - "CachedMultipleNegativesRankingLoss"
        - "MultipleNegativesSymmetricRankingLoss"
        - "CachedMultipleNegativesSymmetricRankingLoss"
        - "MegaBatchMarginLoss"
    - model_name:
        - "all-mpnet-base-v2"
        - "nomic-ai/nomic-embed-text-v1.5"
        - "nomic-ai/nomic-embed-text-v2-moe"
        - "BAAI/bge-base-en-v1.5"
        - "BAAI/bge-large-en-v1.5"
        - "Alibaba-NLP/gte-large-en-v1.5"

matryoshka-2d:
  script: "exp_finetuning_embeddings_matryoshka-2d.py"
  model-parameters:
    - num_train_epochs: [2, 3]
    - experiment_name: "finetuning_embeddings_matryoshka-2d_test"
    - run_name: "test_matryoshka"
    - output_dir: "experiments/results/matryoshka-2d/mpnet-base-all-nli-matryoshka"
    - learning_rate: [5e-4, 2e-5]
    - loss_function:
        - "MultipleNegativesRankingLoss"
        - "MultipleNegativesSymmetricRankingLoss"
    - model_name:
        - "all-mpnet-base-v2"
        - "nomic-ai/nomic-embed-text-v1.5"
        - "nomic-ai/nomic-embed-text-v2-moe"
        - "BAAI/bge-base-en-v1.5"
        - "BAAI/bge-large-en-v1.5"
        - "Alibaba-NLP/gte-large-en-v1.5"
